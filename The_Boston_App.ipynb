{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayl7E5lqeADu"
      },
      "source": [
        "The Boston App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7a7qBkkVrjY",
        "outputId": "39b4cf1b-e1a9-4014-b8f3-92f6a24d2bbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: haversine in /home/briarmoss/.local/lib/python3.10/site-packages (2.8.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/briarmoss/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install haversine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "! pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UuyM154ofHtX",
        "outputId": "8e0c3f7e-d25d-4d59-d09c-af39222e54c3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import requests\n",
        "\n",
        "url = 'https://data.boston.gov/api/3/action/package_list'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    data = response.json()  # Convert JSON response to a Python dictionary\n",
        "else:\n",
        "    print(\"Failed to retrieve data\")\n",
        "    data = {}\n",
        "\n",
        "def fetch_datasets(dataset_ids):\n",
        "    with open('datasets_info.txt', 'w') as file:\n",
        "        for dataset_id in dataset_ids:\n",
        "            url = f'https://data.boston.gov/api/3/action/package_show?id={dataset_id}'\n",
        "            response = requests.get(url)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                file.write(str(data) + '\\n\\n')\n",
        "            else:\n",
        "                file.write(f'Failed to retrieve data for dataset ID {dataset_id}\\n\\n')\n",
        "\n",
        "# Fetch datasets and write to file\n",
        "#fetch_datasets(data['result'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "S2B0JkXPhbq1"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def get_dataset_url(resource_id):\n",
        "    base_url = \"https://data.boston.gov/api/3/action/package_show\"\n",
        "    params = {'id': resource_id}\n",
        "    response = requests.get(base_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        # Assuming the first resource in the package is the one we want\n",
        "        return data['result']['resources'][0]['url']\n",
        "    else:\n",
        "        print(\"Failed to get data:\", response.status_code)\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UvfqFhGAomgR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_dataset_into_dataframe(url):\n",
        "    if url:\n",
        "        return pd.read_csv(url)\n",
        "    else:\n",
        "        print(\"Invalid URL\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRdbofuronQp",
        "outputId": "972485e6-627e-4af3-8f58-63aca639127c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reading Approved Building Permits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_39197/2775520338.py:35: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(data_url, on_bad_lines='warn')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataframe for Approved Building Permits (CSV) created.\n",
            "reading Food Establishment Inspections\n",
            "Dataframe for Food Establishment Inspections (CSV) created.\n",
            "reading Street Sweeping Schedules\n",
            "Dataframe for Street Sweeping Schedules (CSV) created.\n",
            "reading Big Belly Trash Receptacles\n",
            "Dataframe for Big Belly Trash Receptacles (CSV) created.\n",
            "reading Trash Collection Days\n",
            "Dataframe for Trash Collection Days (CSV) created.\n",
            "reading Boston Street Segments\n",
            "Dataframe for Boston Street Segments (CSV) created.\n",
            "reading City Council Roll Call Votes\n",
            "Dataframe for City Council Roll Call Votes (CSV) created.\n",
            "reading Moving Truck Permits\n",
            "Dataframe for Moving Truck Permits (CSV) created.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# List of dataset name IDs\n",
        "datasets = {\n",
        "    'approved-building-permits': 'Approved Building Permits',\n",
        "    'food-establishment-inspections': 'Food Establishment Inspections',\n",
        "    'street-sweeping-schedules': 'Street Sweeping Schedules',\n",
        "    'big-belly-locations': 'Big Belly Trash Receptacles',\n",
        "    'trash-collection-days': 'Trash Collection Days',\n",
        "    'boston-street-segments': 'Boston Street Segments',\n",
        "    'city-council-roll-call-votes': 'City Council Roll Call Votes',\n",
        "    'moving-truck-permits': 'Moving Truck Permits'\n",
        "}\n",
        "\n",
        "\n",
        "dfs = {}\n",
        "\n",
        "# Base URL for the API\n",
        "api_base_url = 'https://data.boston.gov/api/3/action/package_show?id='\n",
        "\n",
        "for dataset_id, dataset_name in datasets.items():\n",
        "    response = requests.get(api_base_url + dataset_id)\n",
        "    if response.status_code == 200:\n",
        "        print(f'reading {dataset_name}')\n",
        "        package = response.json()['result']\n",
        "\n",
        "        # Filter for CSV resources\n",
        "        csv_resources = [resource for resource in package['resources'] if resource['format'].lower() == 'csv']\n",
        "\n",
        "        if csv_resources:\n",
        "            # Assuming the most recent CSV resource is the first in the list\n",
        "            most_recent_csv_resource = csv_resources[0]\n",
        "            data_url = most_recent_csv_resource['url']\n",
        "            df = pd.read_csv(data_url, on_bad_lines='warn')\n",
        "            dfs[dataset_id] = df\n",
        "            print(f'Dataframe for {dataset_name} (CSV) created.')\n",
        "        else:\n",
        "            print(f'No CSV resources found for {dataset_name}.')\n",
        "    else:\n",
        "        print(f'Failed to fetch data for {dataset_name}.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pefK6jTLtHLH"
      },
      "outputs": [],
      "source": [
        "def extract_columns(dataframes_dict):\n",
        "    columns_dict = {}\n",
        "    for dataset_id, df in dataframes_dict.items():\n",
        "        # Extracting column names from each dataframe and storing them as a list\n",
        "        columns_dict[dataset_id] = df.columns.tolist()\n",
        "    return columns_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3Wqk4TwVQW6h"
      },
      "outputs": [],
      "source": [
        "columns_dict = extract_columns(dfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT-o8gHsQges",
        "outputId": "346f6250-f9d4-4b02-bf96-41987ce594b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'approved-building-permits': ['object_id', 'permitnumber', 'worktype', 'permittypedescr', 'description', 'comments', 'applicant', 'declared_valuation', 'total_fees', 'issued_date', 'expiration_date', 'status', 'owner', 'occupancytype', 'sq_feet', 'address', 'city', 'state', 'zip', 'property_id', 'parcel_id', 'gpsy', 'gpsx', 'geom_2249', 'lat', 'long', 'geom_4326'], 'food-establishment-inspections': ['businessname', 'dbaname', 'legalowner', 'namelast', 'namefirst', 'licenseno', 'issdttm', 'expdttm', 'licstatus', 'licensecat', 'descript', 'result', 'resultdttm', 'violation', 'viollevel', 'violdesc', 'violdttm', 'violstatus', 'statusdate', 'comments', 'address', 'city', 'state', 'zip', 'property_id', 'location'], 'street-sweeping-schedules': ['main_id', 'st_name', 'dist', 'dist_name', 'start_time', 'end_time', 'side', 'from', 'to', 'miles', 'section', 'one_way', 'week_1', 'week_2', 'week_3', 'week_4', 'week_5', 'sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'every_day', 'year_round', 'north_end_pilot', 'timestamp', 'parent', 'losta', 'hista'], 'big-belly-locations': ['description', 'Location'], 'trash-collection-days': ['OBJECTID', 'OBJECTID_1', 'RECOLLECT', 'PWDDIST', 'DT', 'TRASHDAY', 'OBJECTID_2', 'CURR_SCHED', 'FUTR_SCHED', 'C_SCH_END', 'F_SCH_STRT', 'Shape_Leng', 'ORIG_FID', 'Shape_Le_1', 'ShapeSTArea', 'ShapeSTLength'], 'boston-street-segments': ['OBJECTID', 'SHAPE', 'SEGMENT_ID', 'L_F_ADD', 'L_T_ADD', 'R_F_ADD', 'R_T_ADD', 'PRE_DIR', 'ST_NAME', 'ST_TYPE', 'SUF_DIR', 'MUN_L', 'MUN_R', 'CFCC', 'SPEEDLIMIT', 'ONEWAY', 'HEIGHT', 'WEIGHT', 'WIDTH', 'F_ZLEV', 'T_ZLEV', 'SHIELD', 'HWY_NUM', 'NBHD_L', 'NBHD_R', 'FT_COST', 'TF_COST', 'TF_DIR', 'FT_DIR', 'STATE00_L', 'STATE00_R', 'COUNTY00_L', 'COUNTY00_R', 'PLACE00_L', 'PLACE00_R', 'TRACT00_L', 'TRACT00_R', 'BLOCK00_L', 'BLOCK00_R', 'MCD00_L', 'MCD00_R', 'STREET_ID', 'SHAPESTLength'], 'city-council-roll-call-votes': ['roll_call_id', 'docket_number', 'subject', 'vote_date', 'councillor', 'vote'], 'moving-truck-permits': ['permit_number', 'work_type', 'permit_type_descr', 'description', 'comments', 'application_method', 'applicant_city', 'applicant_state', 'applicant_zip', 'is_contractor', 'total_fees', 'issued_date', 'expiration_date', 'status', 'occupancy_type', 'city', 'state', 'zip', 'lat', 'long', 'geom_4326']}\n"
          ]
        }
      ],
      "source": [
        "print(columns_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQl0u1z_RnG8",
        "outputId": "d3d550ea-3b89-492f-c3ac-ce287b0bf9fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample data from dataset: approved-building-permits\n",
            "Sample from address:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0          181-183 State ST\n",
            "1         175 W Boundary RD\n",
            "2            15 Prospect ST\n",
            "3      211 W Springfield ST\n",
            "4    14 William Jackson AVE\n",
            "Name: address, dtype: object\n",
            "Sample from city:\n",
            "0          Boston\n",
            "1    West Roxbury\n",
            "2     Charlestown\n",
            "3         Roxbury\n",
            "4        Brighton\n",
            "Name: city, dtype: object\n",
            "Sample from state:\n",
            "0    MA\n",
            "1    MA\n",
            "2    MA\n",
            "3    MA\n",
            "4    MA\n",
            "Name: state, dtype: object\n",
            "Sample from zip:\n",
            "0    2109.0\n",
            "1    2132.0\n",
            "2    2129.0\n",
            "3    2118.0\n",
            "4    2135.0\n",
            "Name: zip, dtype: object\n",
            "Sample from gpsy:\n",
            "0    2.956235e+06\n",
            "1    2.920239e+06\n",
            "2    2.962078e+06\n",
            "3    2.949423e+06\n",
            "4    2.950791e+06\n",
            "Name: gpsy, dtype: float64\n",
            "Sample from gpsx:\n",
            "0    777000.467775\n",
            "1    751016.119559\n",
            "2    775710.380542\n",
            "3    769648.312793\n",
            "4    749690.298790\n",
            "Name: gpsx, dtype: float64\n",
            "Sample from geom_2249:\n",
            "0    0101000020C9080000014080EF50B6274128B89653E58D...\n",
            "1    0101000020C908000081DB363D50EB264164AA649F9747...\n",
            "2    0101000020C90800007E6BD6C23CAC2741422F500F4F99...\n",
            "3    0101000020C9080000025726A0E07C274183505E499780...\n",
            "4    0101000020C9080000FCFDFA98F4E02641F6694F594383...\n",
            "Name: geom_2249, dtype: object\n",
            "Sample from lat:\n",
            "0    42.359190\n",
            "1    42.260750\n",
            "2    42.375243\n",
            "3    42.340600\n",
            "4    42.344600\n",
            "Name: lat, dtype: float64\n",
            "Sample from long:\n",
            "0   -71.052924\n",
            "1   -71.149611\n",
            "2   -71.057585\n",
            "3   -71.080251\n",
            "4   -71.154051\n",
            "Name: long, dtype: float64\n",
            "Sample from geom_4326:\n",
            "0    0101000020E6100000A703291D63C351C074AD05ECF92D...\n",
            "1    0101000020E61000005F23793993C951C071ECAA3E6021...\n",
            "2    0101000020E6100000F053B47AAFC351C0A6BB62F20730...\n",
            "3    0101000020E6100000D72A24D322C551C044521DC4982B...\n",
            "4    0101000020E61000009DED6FF7DBC951C0929A5BD71B2C...\n",
            "Name: geom_4326, dtype: object\n",
            "\n",
            "Sample data from dataset: food-establishment-inspections\n",
            "Sample from address:\n",
            "0    55  COURT ST\n",
            "1    55  COURT ST\n",
            "2    55  COURT ST\n",
            "3    55  COURT ST\n",
            "4    55  COURT ST\n",
            "Name: address, dtype: object\n",
            "Sample from city:\n",
            "0    BOSTON\n",
            "1    BOSTON\n",
            "2    BOSTON\n",
            "3    BOSTON\n",
            "4    BOSTON\n",
            "Name: city, dtype: object\n",
            "Sample from state:\n",
            "0    MA\n",
            "1    MA\n",
            "2    MA\n",
            "3    MA\n",
            "4    MA\n",
            "Name: state, dtype: object\n",
            "Sample from zip:\n",
            "0    2108.0\n",
            "1    2108.0\n",
            "2    2108.0\n",
            "3    2108.0\n",
            "4    2108.0\n",
            "Name: zip, dtype: float64\n",
            "Sample from location:\n",
            "0    (42.359227, -71.058878)\n",
            "1    (42.359227, -71.058878)\n",
            "2    (42.359227, -71.058878)\n",
            "3    (42.359227, -71.058878)\n",
            "4    (42.359227, -71.058878)\n",
            "Name: location, dtype: object\n",
            "\n",
            "Sample data from dataset: street-sweeping-schedules\n",
            "Sample from st_name:\n",
            "0       Ackley Pl\n",
            "1    Arcadia Park\n",
            "2     Ashcroft St\n",
            "3     Boylston St\n",
            "4     Chestnut St\n",
            "Name: st_name, dtype: object\n",
            "Sample from from:\n",
            "0    Washington St\n",
            "1        Draper St\n",
            "2       Perkins St\n",
            "3       Tremont St\n",
            "4        Walnut St\n",
            "Name: from, dtype: object\n",
            "Sample from to:\n",
            "0      Dead End\n",
            "1     Ditson St\n",
            "2    Moraine St\n",
            "3    Charles St\n",
            "4    Charles St\n",
            "Name: to, dtype: object\n",
            "\n",
            "Sample data from dataset: big-belly-locations\n",
            "Sample from Location:\n",
            "0    (42.36034013, -71.05581905)\n",
            "1    (42.37344585, -71.03900682)\n",
            "2    (42.36593588, -71.05833609)\n",
            "3          (42.36112, -71.06296)\n",
            "4      (42.3471459, -71.0882423)\n",
            "Name: Location, dtype: object\n",
            "\n",
            "Sample data from dataset: trash-collection-days\n",
            "No location data columns defined for trash-collection-days\n",
            "\n",
            "Sample data from dataset: boston-street-segments\n",
            "No location data columns defined for boston-street-segments\n",
            "\n",
            "Sample data from dataset: city-council-roll-call-votes\n",
            "No location data columns defined for city-council-roll-call-votes\n",
            "\n",
            "Sample data from dataset: moving-truck-permits\n",
            "Sample from city:\n",
            "0    South Boston\n",
            "1          Boston\n",
            "2     Charlestown\n",
            "3         Roxbury\n",
            "4          Boston\n",
            "Name: city, dtype: object\n",
            "Sample from state:\n",
            "0    MA\n",
            "1    MA\n",
            "2    MA\n",
            "3    MA\n",
            "4    MA\n",
            "Name: state, dtype: object\n",
            "Sample from zip:\n",
            "0    02127\n",
            "1    02113\n",
            "2    02129\n",
            "3    02118\n",
            "4    02115\n",
            "Name: zip, dtype: object\n",
            "Sample from lat:\n",
            "0    42.335807\n",
            "1    42.364200\n",
            "2    42.376534\n",
            "3    42.341280\n",
            "4    42.349870\n",
            "Name: lat, dtype: float64\n",
            "Sample from long:\n",
            "0   -71.036260\n",
            "1   -71.052820\n",
            "2   -71.063113\n",
            "3   -71.077960\n",
            "4   -71.087310\n",
            "Name: long, dtype: float64\n",
            "Sample from geom_4326:\n",
            "0    0101000020E6100000CA89761552C251C04A6249B9FB2A...\n",
            "1    0101000020E6100000C824236761C351C0029A081B9E2E...\n",
            "2    0101000020E6100000F5BC1B0B0AC451C081EA1F443230...\n",
            "3    0101000020E61000005B99F04BFDC451C0B2632310AF2B...\n",
            "4    0101000020E610000048A7AE7C96C551C0FFEC478AC82C...\n",
            "Name: geom_4326, dtype: object\n"
          ]
        }
      ],
      "source": [
        "def print_location_data_samples(dfs):\n",
        "    # Define the location-related columns for each dataset\n",
        "    location_columns = {\n",
        "        'approved-building-permits': ['address', 'city', 'state', 'zip', 'gpsy', 'gpsx', 'geom_2249', 'lat', 'long', 'geom_4326'],\n",
        "        'food-establishment-inspections': ['address', 'city', 'state', 'zip', 'location'],\n",
        "        'street-sweeping-schedules': ['st_name', 'from', 'to'],\n",
        "        'big-belly-locations': ['Location'],\n",
        "        'moving-truck-permits': ['city', 'state', 'zip', 'lat', 'long', 'geom_4326'],\n",
        "        # Add other datasets if needed\n",
        "    }\n",
        "\n",
        "    for dataset_id, df in dfs.items():\n",
        "        print(f\"\\nSample data from dataset: {dataset_id}\")\n",
        "\n",
        "        # Check if the dataset has defined location columns\n",
        "        if dataset_id in location_columns:\n",
        "            for col in location_columns[dataset_id]:\n",
        "                if col in df.columns:\n",
        "                    # Print a sample from the column\n",
        "                    print(f\"Sample from {col}:\")\n",
        "                    print(df[col].dropna().head(5))\n",
        "                else:\n",
        "                    print(f\"Column {col} not found in {dataset_id}\")\n",
        "        else:\n",
        "            print(f\"No location data columns defined for {dataset_id}\")\n",
        "\n",
        "# Example usage\n",
        "# Assume 'dfs' is your dictionary containing dataset IDs as keys and DataFrames as values\n",
        "print_location_data_samples(dfs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vpp8neDpUMHC"
      },
      "outputs": [],
      "source": [
        "def access_approved_building_permits(df):\n",
        "    # Assuming the DataFrame already has 'lat' and 'long' columns\n",
        "    return df\n",
        "\n",
        "def access_location_food_establishment_inspections(df):\n",
        "    # Split the 'location' column into 'lat' and 'long'\n",
        "    df[['lat', 'long']] = df['location'].str.extract(r'\\((.*), (.*)\\)')\n",
        "    df['lat'] = pd.to_numeric(df['lat'], errors='coerce')\n",
        "    df['long'] = pd.to_numeric(df['long'], errors='coerce')\n",
        "    return df\n",
        "\n",
        "def access_location_big_belly_locations(df):\n",
        "    # Split the 'Location' column into 'lat' and 'long'\n",
        "    df[['lat', 'long']] = df['Location'].str.extract(r'\\((.*), (.*)\\)')\n",
        "    df['lat'] = pd.to_numeric(df['lat'], errors='coerce')\n",
        "    df['long'] = pd.to_numeric(df['long'], errors='coerce')\n",
        "    return df\n",
        "\n",
        "def access_moving_truck_permits_location(df):\n",
        "    # Assuming the DataFrame already has 'lat' and 'long' columns\n",
        "    return df\n",
        "\n",
        "# Example usage\n",
        "# Assuming dfs is your dictionary with dataset IDs as keys and DataFrames as values\n",
        "\n",
        "dfs['moving-truck-permits'] = access_moving_truck_permits_location(dfs['moving-truck-permits'])\n",
        "dfs['approved-building-permits'] = access_approved_building_permits(dfs['approved-building-permits'])\n",
        "dfs['food-establishment-inspections'] = access_location_food_establishment_inspections(dfs['food-establishment-inspections'])\n",
        "dfs['big-belly-locations'] = access_location_big_belly_locations(dfs['big-belly-locations'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "p83eJTG4Wk9C"
      },
      "outputs": [],
      "source": [
        "def access_date_approved_building_permits(df):\n",
        "    # Convert 'issued_date' to datetime. If timezone-naive, localize to UTC\n",
        "    df['date'] = pd.to_datetime(df['issued_date'], errors='coerce')\n",
        "    if df['date'].dt.tz is None:\n",
        "        df['date'] = df['date'].dt.tz_localize('UTC')\n",
        "    return df\n",
        "\n",
        "def access_date_food_establishment_inspections(df):\n",
        "    # Convert 'issdttm' to datetime. If timezone-naive, localize to UTC\n",
        "    # for each row check all columns ending in dttm and convert to datetime, then pick the latest one and rename it to date\n",
        "    date_columns = [col for col in df.columns if col.endswith('dttm')]\n",
        "    df[date_columns] = df[date_columns].apply(pd.to_datetime, errors='coerce')\n",
        "    df['date'] = df[date_columns].max(axis=1)\n",
        "    df = df.drop(columns=date_columns)\n",
        "    if df['date'].dt.tz is None:\n",
        "        df['date'] = df['date'].dt.tz_localize('UTC')\n",
        "    \n",
        "    return df\n",
        "\n",
        "def access_date_big_belly_locations(df):\n",
        "    # Assuming this dataset does not have a date column\n",
        "    return df\n",
        "\n",
        "def access_date_moving_truck_permits(df):\n",
        "    # Standardize 'issued_date' to datetime\n",
        "    df['issued_date'] = pd.to_datetime(df['issued_date'], errors='coerce')\n",
        "    if df['issued_date'].dt.tz is None:\n",
        "        df['issued_date'] = df['issued_date'].dt.tz_localize('UTC')\n",
        "    # Standardize 'expiration_date' to datetime\n",
        "    df['expiration_date'] = pd.to_datetime(df['expiration_date'], errors='coerce')\n",
        "    if df['expiration_date'].dt.tz is None:\n",
        "        df['expiration_date'] = df['expiration_date'].dt.tz_localize('UTC')\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage\n",
        "dfs['moving-truck-permits'] = access_date_moving_truck_permits(dfs['moving-truck-permits'])\n",
        "dfs['approved-building-permits'] = access_date_approved_building_permits(dfs['approved-building-permits'])\n",
        "dfs['food-establishment-inspections'] = access_date_food_establishment_inspections(dfs['food-establishment-inspections'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wfCb51ajUUFc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from haversine import haversine\n",
        "\n",
        "def filter_datasets_by_location(dfs, lat, lon, radius, dataset_ids):\n",
        "    def is_within_radius(lat1, lon1, lat2, lon2, radius):\n",
        "        return haversine((lat1, lon1), (lat2, lon2)) <= radius\n",
        "\n",
        "    filtered_dfs = {}\n",
        "    for dataset_id in dataset_ids:\n",
        "        if dataset_id in dfs:\n",
        "            df = dfs[dataset_id]\n",
        "            # Assuming columns 'lat' and 'long' exist and are correctly formatted\n",
        "            if 'lat' in df.columns and 'long' in df.columns:\n",
        "                # Filter the DataFrame\n",
        "                mask = df.apply(lambda row: is_within_radius(lat, lon, row['lat'], row['long'], radius), axis=1)\n",
        "                filtered_dfs[dataset_id] = df[mask]\n",
        "            else:\n",
        "                print(f\"Latitude/Longitude columns not found in {dataset_id}\")\n",
        "\n",
        "    return filtered_dfs\n",
        "\n",
        "# Usage Example\n",
        "# dfs: dictionary with dataset IDs as keys and DataFrames as values\n",
        "# lat, lon: your reference latitude and longitude\n",
        "# radius: radius in kilometers\n",
        "# dataset_ids: list of dataset IDs to filter\n",
        "# result = filter_datasets_by_location(dfs, lat, lon, radius, dataset_ids)\n",
        "\n",
        "#Hilton Boston Park Plaza = 42.3495242,-71.0697654\n",
        "dataset_id_array = ['approved-building-permits','food-establishment-inspections','big-belly-locations','moving-truck-permits']\n",
        "location_filtered_result = filter_datasets_by_location(dfs, 42.3495242,-71.0697654, .25, dataset_id_array)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3JS9XRqW-pr",
        "outputId": "187da4a5-c34e-44c5-d28b-011852d59083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "filtering approved-building-permits\n",
            "filtering food-establishment-inspections\n",
            "filtering big-belly-locations\n",
            "No suitable date column found in big-belly-locations, returning original DataFrame.\n",
            "filtering moving-truck-permits\n"
          ]
        }
      ],
      "source": [
        "def filter_datasets_by_date(dfs, start_date, end_date):\n",
        "    filtered_dfs = {}\n",
        "    for dataset_id, df in dfs.items():\n",
        "        print(f'filtering {dataset_id}')\n",
        "        if 'date' in df.columns:\n",
        "            mask = (df['date'] >= start_date) & (df['date'] <= end_date)\n",
        "        elif 'issued_date' in df.columns and 'expiration_date' in df.columns:\n",
        "            mask = ((df['issued_date'] >= start_date) & (df['issued_date'] <= end_date)) | \\\n",
        "                   ((df['expiration_date'] >= start_date) & (df['expiration_date'] <= end_date))\n",
        "        elif 'issued_date' in df.columns:\n",
        "            mask = (df['issued_date'] >= start_date) & (df['issued_date'] <= end_date)\n",
        "        elif 'expiration_date' in df.columns:\n",
        "            mask = (df['expiration_date'] >= start_date) & (df['expiration_date'] <= end_date)\n",
        "        else:\n",
        "            print(f\"No suitable date column found in {dataset_id}, returning original DataFrame.\")\n",
        "            filtered_dfs[dataset_id] = df\n",
        "            continue\n",
        "\n",
        "        filtered_dfs[dataset_id] = df.loc[mask]\n",
        "    return filtered_dfs\n",
        "\n",
        "# Example usage\n",
        "# start_date and end_date should be pandas Timestamp objects\n",
        "# filtered_dfs = filter_datasets_by_date(dfs, start_date, end_date)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "# start_date and end_date should be pandas Timestamp objects\n",
        "# filtered_dfs = filter_datasets_by_date(dfs, start_date, end_date)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "# Assuming dfs contains datasets processed by both location and date access functions\n",
        "start_date = pd.to_datetime('2023-11-20', utc=True)\n",
        "end_date = pd.to_datetime('2023-11-30', utc=True)\n",
        "date_filtered_result = filter_datasets_by_date(location_filtered_result, start_date, end_date)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HymQAl_6V2yU",
        "outputId": "86baee50-bdb1-4487-e16d-e7d7b496550f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved approved-building-permits to output/approved-building-permits.csv\n",
            "Saved food-establishment-inspections to output/food-establishment-inspections.csv\n",
            "Saved big-belly-locations to output/big-belly-locations.csv\n",
            "Saved moving-truck-permits to output/moving-truck-permits.csv\n"
          ]
        }
      ],
      "source": [
        "def save_dfs_to_csv(dfs, folder_path='output/'):\n",
        "    import os\n",
        "\n",
        "    # Create the folder if it doesn't exist\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "    for dataset_id, df in dfs.items():\n",
        "        file_name = f\"{folder_path}{dataset_id}.csv\"\n",
        "        df.to_csv(file_name, index=False)\n",
        "        print(f\"Saved {dataset_id} to {file_name}\")\n",
        "\n",
        "# Usage\n",
        "# Assuming 'dfs' is your dictionary containing the processed data\n",
        "save_dfs_to_csv(date_filtered_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JwKJ0PeUpm3S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def consolidate_csvs_to_text(csv_files, output_file):\n",
        "    with open(output_file, 'w') as outfile:\n",
        "        for dataset_id, csv_file in csv_files.items():\n",
        "            try:\n",
        "                df = pd.read_csv(csv_file)\n",
        "                outfile.write(f\"Dataset ID: {dataset_id}\\n\")\n",
        "                df.to_string(outfile, header=True, index=False)\n",
        "                outfile.write(\"\\n\\n\")  # Adding a couple of new lines for separation\n",
        "            except Exception as e:\n",
        "                outfile.write(f\"Failed to process {csv_file}: {e}\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yQ2vJjGIpsj2"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "csv_files = {\n",
        "    'approved-building-permits': './output/approved-building-permits.csv',\n",
        "    'food-establishment-inspections': './output/food-establishment-inspections.csv',\n",
        "    'big-belly-locations': './output/big-belly-locations.csv',\n",
        "    'moving-truck-permits' : './output/moving-truck-permits.csv'\n",
        "}\n",
        "consolidate_csvs_to_text(csv_files, 'output/consolidated_data.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOTbN9MrofLk"
      },
      "source": [
        "# Give the data to the Boston GPT for analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1oPBw6nok91"
      },
      "source": [
        "# Let's try another location: Roxbury YMCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf1XBprWokdh",
        "outputId": "b5aa4b11-60b3-40bd-d8b1-a3568056055f"
      },
      "outputs": [],
      "source": [
        "#Roxbury YMCA coordinates 42.318389,-71.0849831\n",
        "\n",
        "#YMCA_location_filtered_result = filter_datasets_by_location(dfs, 42.318389, -71.0849831, .25, dataset_id_array)\n",
        "# Example usage\n",
        "# Assuming dfs contains datasets processed by both location and date access functions\n",
        "#start_date = pd.to_datetime('2023-11-20', utc=True)\n",
        "#end_date = pd.to_datetime('2023-11-30', utc=True)\n",
        "#YMCA_date_filtered_result = filter_datasets_by_date(YMCA_location_filtered_result, start_date, end_date)\n",
        "#save_dfs_to_csv(YMCA_date_filtered_result)\n",
        "\n",
        "# Example usage\n",
        "csv_files = {\n",
        "    'approved-building-permits': './output/approved-building-permits.csv',\n",
        "    'food-establishment-inspections': './output/food-establishment-inspections.csv',\n",
        "    'big-belly-locations': './output/big-belly-locations.csv',\n",
        "    'moving-truck-permits' : './output/moving-truck-permits.csv'\n",
        "}\n",
        "#consolidate_csvs_to_text(csv_files, 'output/ymca_consolidated_data.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletionMessage(content='Report on Activities Affecting the Average Resident, Investor, or Property Owner\\n\\n1. Approved Building Permits:\\n   - Location: 201-241 Stuart St, Boston, MA 2116\\n   - Time and Date: November 20, 2023, at 18:28:17 UTC\\n   - Description: Replacement of a 5 Ton water source heat pump above the meat cooler in the kitchen.\\n\\n2. Approved Building Permits:\\n   - Location: 201-241 Stuart St, Boston, MA 2116\\n   - Time and Date: November 20, 2023, at 18:17:55 UTC\\n   - Description: Replacement of a 10 Ton Water source Heat Pump for the server dining room above the kitchen ceiling.\\n\\n3. Approved Building Permits:\\n   - Location: 27-29 Isabella St, Boston, MA 2116\\n   - Time and Date: November 22, 2023, at 18:23:13 UTC\\n   - Description: Installation of a car charger for Apartment #8, Space #3.\\n\\n4. Approved Building Permits:\\n   - Location: 340-360 Boylston St, Boston, MA 2116\\n   - Time and Date: November 29, 2023, at 18:32:48 UTC\\n   - Description: Core & Shell service, lighting & power.\\n\\n5. Electrical Low Voltage Permit:\\n   - Location: 10-54 Park Pz, Boston, MA 2116\\n   - Time and Date: November 28, 2023, at 13:09:58 UTC\\n   - Description: Installation of a low voltage automation system at DOT2201 State Transport Building.\\n\\n6. Electrical Low Voltage Permit:\\n   - Location: 50 Park PZ, Boston, MA 2116\\n   - Time and Date: November 21, 2023, at 18:04:23 UTC\\n   - Description: New Cat6 data cabling for 12 office/open area locations, 2 WAP locations, and 1 server cabinet location.\\n\\n7. Excavation Permit:\\n   - Location: 52 Providence St, Boston, MA 2116\\n   - Time and Date: November 20, 2023, at 16:37:34 UTC\\n   - Description: New construction at 350 Boylston St, including utility connections and excavation for electrical subcontractor.\\n\\n8. Excavation Permit:\\n   - Location: 0 Berkeley St, Boston, MA 2116\\n   - Time and Date: November 22, 2023, at 14:22:25 UTC\\n   - Description: Relay gas main at Berkeley St @ Beacon St.\\n\\n9. Short Form Building Permit:\\n   - Location: 75 Arlington St, Boston, MA 2116\\n   - Time and Date: November 21, 2023, at 16:40:10 UTC\\n   - Description: Minor works for new security walls, doors, painting & LVT flooring installation.\\n\\n10. Short Form Building Permit:\\n    - Location: 26 Melrose St, Boston, MA 2116\\n    - Time and Date: November 27, 2023, at 15:33:59 UTC\\n    - Description: Repointing rear facade, restoring brownstone sills and lintels, painting fire escapes.\\n\\n11. Moving Truck Permits:\\n    - Location: Stand at curb, Boston, MA 2116\\n    - Time and Date: November 22, 2023, to November 28, 2023\\n    - Description: Permit for moving trucks to occupy street space.\\n\\n12. Moving Truck Permits:\\n    - Location: Stand at curb, Boston, MA 2116\\n    - Time and Date: November 24, 202', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "prompt = \"The following is a list of datasets with records pertinent to a central location. Provide a report of the activities that includes location, time and date specifics, with a focus on what might affect the average resident, investor, or property owner\\n\"\n",
        "\n",
        "with open('output/consolidated_data.txt', 'r') as file:\n",
        "    prompt += file.read()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_response_to_file(response, filename):\n",
        "    with open(filename, 'w') as file:\n",
        "        file.write(response)\n",
        "\n",
        "# Example usage\n",
        "response_content = completion.choices[0].message.content  # Assuming completion is your API response\n",
        "save_response_to_file(response_content, 'gpt3_English_response_output.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Report on Activities Affecting the Average Resident, Investor, or Property '\n",
            " 'Owner\\n'\n",
            " '\\n'\n",
            " '1. Approved Building Permits:\\n'\n",
            " '   - Location: 201-241 Stuart St, Boston, MA 2116\\n'\n",
            " '   - Time and Date: November 20, 2023, at 18:28:17 UTC\\n'\n",
            " '   - Description: Replacement of a 5 Ton water source heat pump above the '\n",
            " 'meat cooler in the kitchen.\\n'\n",
            " '\\n'\n",
            " '2. Approved Building Permits:\\n'\n",
            " '   - Location: 201-241 Stuart St, Boston, MA 2116\\n'\n",
            " '   - Time and Date: November 20, 2023, at 18:17:55 UTC\\n'\n",
            " '   - Description: Replacement of a 10 Ton Water source Heat Pump for the '\n",
            " 'server dining room above the kitchen ceiling.\\n'\n",
            " '\\n'\n",
            " '3. Approved Building Permits:\\n'\n",
            " '   - Location: 27-29 Isabella St, Boston, MA 2116\\n'\n",
            " '   - Time and Date: November 22, 2023, at 18:23:13 UTC\\n'\n",
            " '   - Description: Installation of a car charger for Apartment #8, Space #3.\\n'\n",
            " '\\n'\n",
            " '4. Approved Building Permits:\\n'\n",
            " '   - Location: 340-360 Boylston St, Boston, MA 2116\\n'\n",
            " '   - Time and Date: November 29, 2023, at 18:32:48 UTC\\n'\n",
            " '   - Description: Core & Shell service, lighting & power.\\n'\n",
            " '\\n'\n",
            " '5. Electrical Low Voltage Permit:\\n'\n",
            " '   - Location: 10-54 Park Pz, Boston, MA 2116\\n'\n",
            " '   - Time and Date: November 28, 2023, at 13:09:58 UTC\\n'\n",
            " '   - Description: Installation of a low voltage automation system at DOT2201 '\n",
            " 'State Transport Building.\\n'\n",
            " '\\n'\n",
            " '6. Electrical Low Voltage Permit:\\n'\n",
            " '   - Location: 50 Park PZ, Boston, MA 2116\\n'\n",
            " '   - Time and Date: November 21, 2023, at 18:04:23 UTC\\n'\n",
            " '   - Description: New Cat6 data cabling for 12 office/open area locations, 2 '\n",
            " 'WAP locations, and 1 server cabinet location.\\n'\n",
            " '\\n'\n",
            " '7. Excavation Permit:\\n'\n",
            " '   - Location: 52 Providence St, Boston, MA 2116\\n'\n",
            " '   - Time and Date: November 20, 2023, at 16:37:34 UTC\\n'\n",
            " '   - Description: New construction at 350 Boylston St, including utility '\n",
            " 'connections and excavation for electrical subcontractor.\\n'\n",
            " '\\n'\n",
            " '8. Excavation Permit:\\n'\n",
            " '   - Location: 0 Berkeley St, Boston, MA 2116\\n'\n",
            " '   - Time and Date: November 22, 2023, at 14:22:25 UTC\\n'\n",
            " '   - Description: Relay gas main at Berkeley St @ Beacon St.\\n'\n",
            " '\\n'\n",
            " '9. Short Form Building Permit:\\n'\n",
            " '   - Location: 75 Arlington St, Boston, MA 2116\\n'\n",
            " '   - Time and Date: November 21, 2023, at 16:40:10 UTC\\n'\n",
            " '   - Description: Minor works for new security walls, doors, painting & LVT '\n",
            " 'flooring installation.\\n'\n",
            " '\\n'\n",
            " '10. Short Form Building Permit:\\n'\n",
            " '    - Location: 26 Melrose St, Boston, MA 2116\\n'\n",
            " '    - Time and Date: November 27, 2023, at 15:33:59 UTC\\n'\n",
            " '    - Description: Repointing rear facade, restoring brownstone sills and '\n",
            " 'lintels, painting fire escapes.\\n'\n",
            " '\\n'\n",
            " '11. Moving Truck Permits:\\n'\n",
            " '    - Location: Stand at curb, Boston, MA 2116\\n'\n",
            " '    - Time and Date: November 22, 2023, to November 28, 2023\\n'\n",
            " '    - Description: Permit for moving trucks to occupy street space.\\n'\n",
            " '\\n'\n",
            " '12. Moving Truck Permits:\\n'\n",
            " '    - Location: Stand at curb, Boston, MA 2116\\n'\n",
            " '    - Time and Date: November 24, 202')\n"
          ]
        }
      ],
      "source": [
        "#output the response in human readable format\n",
        "from pprint import pprint\n",
        "\n",
        "pprint(response_content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
